{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "886a5c08",
   "metadata": {},
   "source": [
    "[Episode 1](https://www.youtube.com/watch?v=OMDn66kM9Qc&list=PLaMu-SDt_RB5NUm67hU2pdE75j6KaIOv2&index=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc3b128",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import random_split, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e59e940",
   "metadata": {},
   "source": [
    "# Pytorch Lightning\n",
    "\n",
    "1. model\n",
    "2. optimizer\n",
    "3. data\n",
    "4. training loop \"the magic\"\n",
    "5. validation loop \"the validation magic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7baab03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf37e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, batch_size=32):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "     \n",
    "    \n",
    "    def prepare_data(self):\n",
    "        datasets.MNIST('data', train=True, download=True, transform=transforms.ToTensor())\n",
    "        datasets.MNIST('data', train=False, download=True, transform=transforms.ToTensor())\n",
    "        \n",
    "        \n",
    "    def setup(self, stage):\n",
    "        # transformation\n",
    "        dataset = datasets.MNIST('data', train=True, download=False, transform=transforms.ToTensor())\n",
    "        self.test_dataset = datasets.MNIST('data', train=False, download=False, transform=transforms.ToTensor())\n",
    "        self.train_dataset, self.val_dataset = random_split(dataset, [55000, 5000])\n",
    "    \n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        train_loader = DataLoader(self.train_dataset, batch_size=self.batch_size)\n",
    "        return train_loader\n",
    "    \n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        val_loader = DataLoader(self.val_dataset, batch_size=self.batch_size)\n",
    "        return val_loader\n",
    "    \n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        test_loader = DataLoader(self.test_dataset, batch_size=self.batch_size)\n",
    "        return test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7677001",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(28 * 28 , 64)\n",
    "        self.l2 = nn.Linear(64, 64)\n",
    "        self.l3 = nn.Linear(64, 10)\n",
    "        self.do = nn.Dropout(0.1)\n",
    "        \n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h1 = F.relu(self.l1(x))\n",
    "        h2 = F.relu(self.l2(h1))\n",
    "        do = self.do(h2 + h1)\n",
    "        logits = self.l3(do)\n",
    "        return logits\n",
    "    \n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.SGD(self.parameters(), lr=1e-2)\n",
    "        return optimizer\n",
    "    \n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        \n",
    "        b = x.size(0)\n",
    "        x = x.view(b, -1)\n",
    "        \n",
    "        logits = self(x) # l: logit\n",
    "        # import pdb; pdb.set_trace()\n",
    "        \n",
    "        J = self.loss(logits, y) # J: loss value\n",
    "        \n",
    "        acc = torchmetrics.functional.accuracy(logits, y)\n",
    "        #pbar = {'train_acc': acc}\n",
    "        self.log('train_acc', acc, on_step=True, on_epoch=False, prog_bar=True, sync_dist=True)\n",
    "        #return {'loss': J, 'progress_bar': pbar}\n",
    "        return {'loss': J}\n",
    "    \n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        \n",
    "        b = x.size(0)\n",
    "        x = x.view(b, -1)\n",
    "        \n",
    "        logits = self(x) # l: logit\n",
    "        # import pdb; pdb.set_trace()\n",
    "        \n",
    "        J = self.loss(logits, y) # J: loss value\n",
    "        \n",
    "        acc = torchmetrics.functional.accuracy(logits, y)\n",
    "        #pbar = {'val_acc': acc}\n",
    "        self.log('val_acc', acc, on_step=False, on_epoch=True, prog_bar=True, sync_dist=True)\n",
    "        #return {'loss': J, 'progress_bar': pbar}\n",
    "        return {'loss': J}\n",
    "    \n",
    "    \n",
    "    def validation_epoch_end(self, val_step_outputs):\n",
    "        # [results, results, results, results]\n",
    "        avg_val_loss = torch.tensor([x['loss'] for x in val_step_outputs]).mean()\n",
    "        #avg_val_acc = torch.tensor([x['progress_bar']['val_acc'] for x in val_step_outputs]).mean()\n",
    "        #pbar = {'avg_val_acc': avg_val_acc}\n",
    "        #return {'val_loss': avg_val_loss, 'progress_bar': pbar}\n",
    "        return {'val_loss': avg_val_loss}\n",
    "    \n",
    "    # Overwrite\n",
    "    # def backward(self, trainer, loss, optimizer, optimizer_idx):\n",
    "    #     loss.backward()\n",
    "    \n",
    "model = ResNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4bdf59",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mnist_dm = MNISTDataModule()\n",
    "\n",
    "trainer = pl.Trainer(progress_bar_refresh_rate=20,\n",
    "                     max_epochs=5,\n",
    "                     gpus=2,\n",
    "                     num_nodes=1, accelerator=\"dp\") # progress bar update 느리게\n",
    "# trainer = pl.Trainer()\n",
    "outputs = trainer.fit(model, mnist_dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af333c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls lightning_logs/version_2/checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bb5160",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        self.resnet = ResNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f4b7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.MNIST('data', train=True, download=False, transform=transforms.ToTensor())\n",
    "train, val = random_split(train_data, [55000, 5000])\n",
    "train_loader = DataLoader(train, batch_size=32)\n",
    "val_loader = DataLoader(val, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602e33bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(28 * 28, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.1),\n",
    "    nn.Linear(64, 10)\n",
    ")\n",
    "\n",
    "model.to('cuda:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93488eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(28 * 28 , 64)\n",
    "        self.l2 = nn.Linear(64, 64)\n",
    "        self.l3 = nn.Linear(64, 10)\n",
    "        self.do = nn.Dropout(0.1)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        h1 = F.relu(self.l1(x))\n",
    "        h2 = F.relu(self.l2(h1))\n",
    "        do = self.do(h2 + h1)\n",
    "        logits = self.l3(do)\n",
    "        return logits\n",
    "\n",
    "model = ResNet().to('cuda:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e210452",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = model.parameters()\n",
    "optimiser = optim.SGD(params, lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ad5dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500681b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epochs = 5\n",
    "for epoch in range(nb_epochs):\n",
    "    losses = list()\n",
    "    accuracies = list()\n",
    "    model.train()\n",
    "    for batch in train_loader:\n",
    "        x, y = batch\n",
    "        \n",
    "        b = x.size(0)\n",
    "        x = x.view(b, -1).to('cuda:1')\n",
    "        \n",
    "        l = model(x) # l: logit\n",
    "        # import pdb; pdb.set_trace()\n",
    "        \n",
    "        J = loss(l, y.to('cuda:1')) # J: loss value\n",
    "        model.zero_grad()\n",
    "        J.backward()\n",
    "        optimiser.step()\n",
    "        \n",
    "        losses.append(J.item())\n",
    "        accuracies.append(y.eq(l.detach().argmax(dim=1).cpu()).float().mean())\n",
    "    \n",
    "    print(f'Epoch {epoch + 1}', end=', ')\n",
    "    print(f'training loss: {torch.tensor(losses).mean():.2f}', end=', ')\n",
    "    print(f'training accuracy: {torch.tensor(accuracies).mean():.2f}')\n",
    "    \n",
    "    losses = list()\n",
    "    accuracies = list()\n",
    "    model.eval()\n",
    "    for batch in val_loader:\n",
    "        x, y = batch\n",
    "        \n",
    "        b = x.size(0)\n",
    "        x = x.view(b, -1).to('cuda:1')\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            l = model(x) # l: logit\n",
    "        J = loss(l, y.to('cuda:1')) # J: loss value\n",
    "        \n",
    "        losses.append(J.item())\n",
    "        accuracies.append(y.eq(l.detach().argmax(dim=1).cpu()).float().mean())\n",
    "        \n",
    "    print(f'Epoch {epoch + 1}', end=', ')\n",
    "    print(f'validation loss: {torch.tensor(losses).mean():.2f}', end=', ')\n",
    "    print(f'validation accuracy: {torch.tensor(accuracies).mean():.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae96c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
